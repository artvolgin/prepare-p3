{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10b9f2c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/social_determinants_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add project root to Python path\n",
    "sys.path.append('../')  # Add project root to Python path\n",
    "\n",
    "# Import our pipeline\n",
    "from src.pipeline.pipeline_runner import PipelineRunner\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Load combined dataset and create sample dataset\n",
    "df_combined = pd.read_pickle('../data/processed/df_combined.pkl')\n",
    "df_combined_sample = df_combined.sample(1000, random_state=42)\n",
    "df_combined_sample.to_pickle('../data/processed/df_combined_sample.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12685fe",
   "metadata": {},
   "source": [
    "# 1. End-to-End Pipeline Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02214f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Example 1: End-to-End Pipeline ===\n",
      "=== Starting Full Pipeline ===\n",
      "Loading data...\n",
      "Using random 0.2 split...\n",
      "Train set: 800 samples\n",
      "Test set: 200 samples\n",
      "Running data preprocessing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/social_determinants_env/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:246: UserWarning: Found unknown categories in columns [5, 7, 10, 74, 107, 110, 116, 117] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 19:29:45,397] A new study created in memory with name: no-name-9690593b-a90e-4b0b-b874-b0c2fddfaf74\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing complete. Features: 568\n",
      "Training LGBM model...\n",
      "  Optimizing lgbm hyperparameters...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[33]\tvalid_0's rmse: 0.673622\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's rmse: 0.787725\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-15 19:29:47,845] Trial 0 finished with value: 0.5233249867519968 and parameters: {'lambda_l1': 0.024289169469748875, 'lambda_l2': 3.2859708169642414, 'num_leaves': 99, 'feature_fraction': 0.8394633936788146, 'bagging_fraction': 0.6468055921327309, 'bagging_freq': 1, 'min_child_samples': 12, 'learning_rate': 0.146962368105409}. Best is trial 0 with value: 0.5233249867519968.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's rmse: 0.6685\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[81]\tvalid_0's rmse: 0.658164\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-15 19:29:50,662] Trial 1 finished with value: 0.5035678610523731 and parameters: {'lambda_l1': 0.16730402817820234, 'lambda_l2': 0.4160439645256604, 'num_leaves': 22, 'feature_fraction': 0.9879639408647978, 'bagging_fraction': 0.8497327922401265, 'bagging_freq': 1, 'min_child_samples': 17, 'learning_rate': 0.03050945891610522}. Best is trial 1 with value: 0.5035678610523731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[99]\tvalid_0's rmse: 0.740006\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[77]\tvalid_0's rmse: 0.657323\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[80]\tvalid_0's rmse: 0.718042\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[65]\tvalid_0's rmse: 0.66403\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[95]\tvalid_0's rmse: 0.763226\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-15 19:29:52,974] Trial 2 finished with value: 0.4974375250601743 and parameters: {'lambda_l1': 0.01334697757417809, 'lambda_l2': 0.08730885649333642, 'num_leaves': 67, 'feature_fraction': 0.7164916560792167, 'bagging_fraction': 0.7835558684167139, 'bagging_freq': 1, 'min_child_samples': 21, 'learning_rate': 0.04649345697900868}. Best is trial 2 with value: 0.4974375250601743.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's rmse: 0.664192\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[99]\tvalid_0's rmse: 0.709308\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's rmse: 0.760532\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-15 19:29:54,552] Trial 3 finished with value: 0.4952746594299272 and parameters: {'lambda_l1': 0.04863951003835899, 'lambda_l2': 0.8023102291340046, 'num_leaves': 41, 'feature_fraction': 0.8056937753654446, 'bagging_fraction': 0.7777243706586128, 'bagging_freq': 1, 'min_child_samples': 34, 'learning_rate': 0.029617890239950373}. Best is trial 3 with value: 0.4952746594299272.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's rmse: 0.725761\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[99]\tvalid_0's rmse: 0.654564\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[58]\tvalid_0's rmse: 0.646849\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-15 19:29:55,803] Trial 4 finished with value: 0.48142056610125794 and parameters: {'lambda_l1': 0.0017402990823522548, 'lambda_l2': 3.235185145617431, 'num_leaves': 125, 'feature_fraction': 0.9233589392465844, 'bagging_fraction': 0.6913841307520112, 'bagging_freq': 1, 'min_child_samples': 38, 'learning_rate': 0.05510391929902154}. Best is trial 4 with value: 0.48142056610125794.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[99]\tvalid_0's rmse: 0.710159\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\tvalid_0's rmse: 0.65519\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-15 19:29:57,687] Trial 5 finished with value: 0.4932084235116639 and parameters: {'lambda_l1': 0.002827585657311758, 'lambda_l2': 0.06786479434196534, 'num_leaves': 23, 'feature_fraction': 0.9637281608315128, 'bagging_fraction': 0.677633994480005, 'bagging_freq': 2, 'min_child_samples': 22, 'learning_rate': 0.06623659776144764}. Best is trial 4 with value: 0.48142056610125794.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[69]\tvalid_0's rmse: 0.719361\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\tvalid_0's rmse: 0.654342\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's rmse: 0.750436\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\tvalid_0's rmse: 0.664224\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\tvalid_0's rmse: 0.771306\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-15 19:29:59,069] Trial 6 finished with value: 0.5093660392916048 and parameters: {'lambda_l1': 0.105260377776104, 'lambda_l2': 0.0048280425192712886, 'num_leaves': 125, 'feature_fraction': 0.9100531293444458, 'bagging_fraction': 0.8818496824692568, 'bagging_freq': 3, 'min_child_samples': 34, 'learning_rate': 0.16707221510623524}. Best is trial 4 with value: 0.48142056610125794.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[96]\tvalid_0's rmse: 0.720697\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[99]\tvalid_0's rmse: 0.661202\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's rmse: 0.646215\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-15 19:30:00,277] Trial 7 finished with value: 0.4894836019603163 and parameters: {'lambda_l1': 0.002124863863243128, 'lambda_l2': 0.005308046630775945, 'num_leaves': 24, 'feature_fraction': 0.7301321323053057, 'bagging_fraction': 0.7166031869068445, 'bagging_freq': 1, 'min_child_samples': 43, 'learning_rate': 0.04547611147126364}. Best is trial 4 with value: 0.48142056610125794.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's rmse: 0.732461\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-15 19:30:01,286] Trial 8 finished with value: 0.5027633294110772 and parameters: {'lambda_l1': 0.010943804457233497, 'lambda_l2': 0.10172238474449048, 'num_leaves': 35, 'feature_fraction': 0.9208787923016158, 'bagging_fraction': 0.6223651931039312, 'bagging_freq': 3, 'min_child_samples': 41, 'learning_rate': 0.031604263728207765}. Best is trial 4 with value: 0.48142056610125794.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's rmse: 0.746966\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's rmse: 0.662284\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-15 19:30:03,343] Trial 9 finished with value: 0.5051376883780595 and parameters: {'lambda_l1': 0.0010481565330759974, 'lambda_l2': 1.0384064176934509, 'num_leaves': 97, 'feature_fraction': 0.8916028672163949, 'bagging_fraction': 0.8313811040057837, 'bagging_freq': 1, 'min_child_samples': 24, 'learning_rate': 0.02611554269799446}. Best is trial 4 with value: 0.48142056610125794.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's rmse: 0.734304\n",
      "  Parameters optimized\n",
      "  Fitting lgbm model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/social_determinants_env/lib/python3.11/site-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
      "  _log_warning(\"Only training set found, disabling early stopping.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  lgbm model saved\n",
      "  Generating lgbm predictions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-15 19:30:06,828] A new study created in memory with name: no-name-ed1802b7-e8ec-4e96-847c-690e3dd49768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  lgbm predictions saved\n",
      "Training CATB model...\n",
      "  Optimizing catb hyperparameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-15 19:30:07,804] Trial 0 finished with value: 0.49729263054409883 and parameters: {'depth': 5, 'learning_rate': 0.1785436060870726, 'l2_leaf_reg': 5.395030966670228, 'bagging_temperature': 0.2993292420985183}. Best is trial 0 with value: 0.49729263054409883.\n",
      "[I 2025-07-15 19:30:08,566] Trial 1 finished with value: 0.546967354976403 and parameters: {'depth': 4, 'learning_rate': 0.02864339657822303, 'l2_leaf_reg': 1.1430983876313219, 'bagging_temperature': 0.4330880728874676}. Best is trial 0 with value: 0.49729263054409883.\n",
      "[I 2025-07-15 19:30:09,881] Trial 2 finished with value: 0.49912022773787246 and parameters: {'depth': 6, 'learning_rate': 0.10211806418789517, 'l2_leaf_reg': 1.0485387725194617, 'bagging_temperature': 0.48495492608099716}. Best is trial 0 with value: 0.49729263054409883.\n",
      "[I 2025-07-15 19:30:11,866] Trial 3 finished with value: 0.5156374799069744 and parameters: {'depth': 7, 'learning_rate': 0.03261137469244295, 'l2_leaf_reg': 1.5199348301309807, 'bagging_temperature': 0.09170225492671691}. Best is trial 0 with value: 0.49729263054409883.\n",
      "[I 2025-07-15 19:30:12,876] Trial 4 finished with value: 0.49986230700551654 and parameters: {'depth': 5, 'learning_rate': 0.06695552617031866, 'l2_leaf_reg': 2.7036160666620015, 'bagging_temperature': 0.14561457009902096}. Best is trial 0 with value: 0.49729263054409883.\n",
      "[I 2025-07-15 19:30:14,228] Trial 5 finished with value: 0.5345966715381458 and parameters: {'depth': 6, 'learning_rate': 0.027575529238707534, 'l2_leaf_reg': 1.9594972058679163, 'bagging_temperature': 0.18318092164684585}. Best is trial 0 with value: 0.49729263054409883.\n",
      "[I 2025-07-15 19:30:15,172] Trial 6 finished with value: 0.49228430661459566 and parameters: {'depth': 5, 'learning_rate': 0.12195678219063029, 'l2_leaf_reg': 1.5837031559118748, 'bagging_temperature': 0.2571172192068058}. Best is trial 6 with value: 0.49228430661459566.\n",
      "[I 2025-07-15 19:30:16,489] Trial 7 finished with value: 0.5692878371979371 and parameters: {'depth': 6, 'learning_rate': 0.022257706349811456, 'l2_leaf_reg': 4.050837781329674, 'bagging_temperature': 0.08526206184364576}. Best is trial 6 with value: 0.49228430661459566.\n",
      "[I 2025-07-15 19:30:17,184] Trial 8 finished with value: 0.5046877862830282 and parameters: {'depth': 4, 'learning_rate': 0.1777933581403786, 'l2_leaf_reg': 9.23915031962725, 'bagging_temperature': 0.40419867405823057}. Best is trial 6 with value: 0.49228430661459566.\n",
      "[I 2025-07-15 19:30:18,127] Trial 9 finished with value: 0.5621124512540027 and parameters: {'depth': 5, 'learning_rate': 0.025043908574120786, 'l2_leaf_reg': 4.833180632488465, 'bagging_temperature': 0.22007624686980065}. Best is trial 6 with value: 0.49228430661459566.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Parameters optimized\n",
      "  Fitting catb model...\n",
      "  catb model saved\n",
      "  Generating catb predictions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-15 19:30:20,756] A new study created in memory with name: no-name-e741226b-4013-4548-b0e4-84cbea6e4ec2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  catb predictions saved\n",
      "Training XGBM model...\n",
      "  Optimizing xgbm hyperparameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-15 19:30:22,603] Trial 0 finished with value: 0.5403471132133384 and parameters: {'max_depth': 5, 'learning_rate': 0.1785436060870726, 'subsample': 0.892797576724562, 'colsample_bytree': 0.8394633936788146, 'reg_alpha': 0.0029380279387035343, 'reg_lambda': 0.026364803038431653}. Best is trial 0 with value: 0.5403471132133384.\n",
      "[I 2025-07-15 19:30:24,420] Trial 1 finished with value: 0.5013058877116958 and parameters: {'max_depth': 4, 'learning_rate': 0.146962368105409, 'subsample': 0.8404460046972835, 'colsample_bytree': 0.8832290311184181, 'reg_alpha': 0.00115279871282324, 'reg_lambda': 4.147225000481636}. Best is trial 1 with value: 0.5013058877116958.\n",
      "[I 2025-07-15 19:30:27,252] Trial 2 finished with value: 0.5322434549188729 and parameters: {'max_depth': 7, 'learning_rate': 0.03261137469244295, 'subsample': 0.6727299868828402, 'colsample_bytree': 0.6733618039413735, 'reg_alpha': 0.008179499475211672, 'reg_lambda': 0.2607965659809584}. Best is trial 1 with value: 0.5013058877116958.\n",
      "[I 2025-07-15 19:30:29,479] Trial 3 finished with value: 0.5242362973999866 and parameters: {'max_depth': 5, 'learning_rate': 0.039107417325490494, 'subsample': 0.8447411578889518, 'colsample_bytree': 0.6557975442608167, 'reg_alpha': 0.007523742884534853, 'reg_lambda': 0.09745399020374085}. Best is trial 1 with value: 0.5013058877116958.\n",
      "[I 2025-07-15 19:30:31,495] Trial 4 finished with value: 0.5257883111540781 and parameters: {'max_depth': 5, 'learning_rate': 0.12195678219063029, 'subsample': 0.6798695128633439, 'colsample_bytree': 0.8056937753654446, 'reg_alpha': 0.05987474910461398, 'reg_lambda': 0.013346527038305937}. Best is trial 1 with value: 0.5013058877116958.\n",
      "[I 2025-07-15 19:30:34,091] Trial 5 finished with value: 0.5115806974101986 and parameters: {'max_depth': 6, 'learning_rate': 0.029617890239950373, 'subsample': 0.6260206371941118, 'colsample_bytree': 0.9795542149013333, 'reg_alpha': 0.7886714129990487, 'reg_lambda': 1.519988122008397}. Best is trial 1 with value: 0.5013058877116958.\n",
      "[I 2025-07-15 19:30:36,406] Trial 6 finished with value: 0.5351617913785771 and parameters: {'max_depth': 5, 'learning_rate': 0.025043908574120786, 'subsample': 0.8736932106048627, 'colsample_bytree': 0.7760609974958406, 'reg_alpha': 0.002323350351539011, 'reg_lambda': 0.21700394405050152}. Best is trial 1 with value: 0.5013058877116958.\n",
      "[I 2025-07-15 19:30:38,110] Trial 7 finished with value: 0.5227395929974393 and parameters: {'max_depth': 4, 'learning_rate': 0.16231191351941007, 'subsample': 0.7035119926400067, 'colsample_bytree': 0.8650089137415928, 'reg_alpha': 0.00861257919259488, 'reg_lambda': 0.25330746540014476}. Best is trial 1 with value: 0.5013058877116958.\n",
      "[I 2025-07-15 19:30:40,790] Trial 8 finished with value: 0.543748211814513 and parameters: {'max_depth': 6, 'learning_rate': 0.030611488731000357, 'subsample': 0.9878338511058234, 'colsample_bytree': 0.9100531293444458, 'reg_alpha': 0.6584106160121609, 'reg_lambda': 2.6008312687264885}. Best is trial 1 with value: 0.5013058877116958.\n",
      "[I 2025-07-15 19:30:42,825] Trial 9 finished with value: 0.562226861466101 and parameters: {'max_depth': 6, 'learning_rate': 0.16707221510623524, 'subsample': 0.6353970008207678, 'colsample_bytree': 0.6783931449676581, 'reg_alpha': 0.0013667272915456222, 'reg_lambda': 0.07551909976018513}. Best is trial 1 with value: 0.5013058877116958.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Parameters optimized\n",
      "  Fitting xgbm model...\n",
      "  xgbm model saved\n",
      "  Generating xgbm predictions...\n",
      "  xgbm predictions saved\n",
      "Training ensemble model...\n",
      "Ensemble training complete\n",
      "Final predictions saved to: predictions_example_full.pkl\n",
      "=== Pipeline Complete ===\n"
     ]
    }
   ],
   "source": [
    "# 1. End-to-End Pipeline Run with SHAP and CI\n",
    "print(\"=== Example 1: End-to-End Pipeline ===\")\n",
    "\n",
    "# Initialize pipeline with all features enabled\n",
    "runner = PipelineRunner(\n",
    "    data_dir='../data',\n",
    "    models_dir='../models',\n",
    "    run_name='example_full',\n",
    "    df_combined_path='../data/processed/df_combined_sample.pkl',\n",
    "    variables_type_path='../data/variables/table_variables_type.xlsx',\n",
    "    return_shap=True,\n",
    "    return_ci=True\n",
    ")\n",
    "\n",
    "# Run full pipeline\n",
    "predictions_full = runner.run_full_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72d5a92c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'y_lgbm_train':                               y  \\\n",
       " id_resp                           \n",
       " us_912065010           0.368730   \n",
       " us_906682010           0.094521   \n",
       " india_119120400390101  0.760381   \n",
       " mexico_1232510        -1.056103   \n",
       " us_54616040           -0.763942   \n",
       " ...                         ...   \n",
       " mexico_302210         -0.891004   \n",
       " us_111640010           0.542360   \n",
       " india_129194300390101 -0.716868   \n",
       " india_105025300020101 -0.476749   \n",
       " us_46686020            0.757812   \n",
       " \n",
       "                                                                     shap  \n",
       " id_resp                                                                   \n",
       " us_912065010           {'country': 0.0, 'h1atotb': -0.003695740641128...  \n",
       " us_906682010           {'country': 0.0, 'h1atotb': 0.0005909464479372...  \n",
       " india_119120400390101  {'country': 0.0, 'h1atotb': 0.0008810666362923...  \n",
       " mexico_1232510         {'country': 0.0, 'h1atotb': -0.003453383142535...  \n",
       " us_54616040            {'country': 0.0, 'h1atotb': 0.0053985497881809...  \n",
       " ...                                                                  ...  \n",
       " mexico_302210          {'country': 0.0, 'h1atotb': 0.0060761111587250...  \n",
       " us_111640010           {'country': 0.0, 'h1atotb': -0.007969849371048...  \n",
       " india_129194300390101  {'country': 0.0, 'h1atotb': 0.0005909464479372...  \n",
       " india_105025300020101  {'country': 0.0, 'h1atotb': 0.0021813394205695...  \n",
       " us_46686020            {'country': 0.0, 'h1atotb': 0.0112399691207069...  \n",
       " \n",
       " [800 rows x 2 columns],\n",
       " 'y_lgbm_test':                               y  \\\n",
       " id_resp                           \n",
       " us_74521010           -1.424929   \n",
       " mexico_787110         -1.850872   \n",
       " india_127182900171605  0.448512   \n",
       " india_105022700550102 -0.129449   \n",
       " india_124155301820102 -0.811478   \n",
       " ...                         ...   \n",
       " us_15189010           -0.538464   \n",
       " india_133219200780101  1.420756   \n",
       " us_500587010           0.102965   \n",
       " india_109062300150101 -0.844205   \n",
       " us_38520010           -0.026300   \n",
       " \n",
       "                                                                     shap  \\\n",
       " id_resp                                                                    \n",
       " us_74521010            {'country': 0.004235812351906297, 'h1atotb': 0...   \n",
       " mexico_787110          {'country': -0.0037562864252753945, 'h1atotb':...   \n",
       " india_127182900171605  {'country': -0.0037562864252753945, 'h1atotb':...   \n",
       " india_105022700550102  {'country': -0.0010899125641613014, 'h1atotb':...   \n",
       " india_124155301820102  {'country': -0.0012548112238435264, 'h1atotb':...   \n",
       " ...                                                                  ...   \n",
       " us_15189010            {'country': 0.004235812351906297, 'h1atotb': 0...   \n",
       " india_133219200780101  {'country': -0.0004968739921203247, 'h1atotb':...   \n",
       " us_500587010           {'country': 0.0003905218281042001, 'h1atotb': ...   \n",
       " india_109062300150101  {'country': -0.0009611288469828569, 'h1atotb':...   \n",
       " us_38520010            {'country': 0.004235812351906297, 'h1atotb': -...   \n",
       " \n",
       "                         y_lower   y_upper  \n",
       " id_resp                                    \n",
       " us_74521010           -2.796465 -0.207399  \n",
       " mexico_787110         -3.149784 -0.504281  \n",
       " india_127182900171605 -0.775987  1.841267  \n",
       " india_105022700550102 -1.480530  1.140227  \n",
       " india_124155301820102 -2.032391  0.554990  \n",
       " ...                         ...       ...  \n",
       " us_15189010           -1.925904  0.686403  \n",
       " india_133219200780101 -0.004649  2.599921  \n",
       " us_500587010          -1.052054  1.543280  \n",
       " india_109062300150101 -2.140793  0.437963  \n",
       " us_38520010           -1.206073  1.383214  \n",
       " \n",
       " [200 rows x 4 columns],\n",
       " 'y_catb_train':                               y  \\\n",
       " id_resp                           \n",
       " us_912065010           0.523534   \n",
       " us_906682010          -0.009688   \n",
       " india_119120400390101  0.742801   \n",
       " mexico_1232510        -0.822104   \n",
       " us_54616040           -0.474589   \n",
       " ...                         ...   \n",
       " mexico_302210         -0.824460   \n",
       " us_111640010           0.776031   \n",
       " india_129194300390101 -0.495018   \n",
       " india_105025300020101 -0.723954   \n",
       " us_46686020            0.801333   \n",
       " \n",
       "                                                                     shap  \n",
       " id_resp                                                                   \n",
       " us_912065010           {'country': 0.0, 'h1atotb': 0.0, 'h1child': 0....  \n",
       " us_906682010           {'country': 0.003970272608674365, 'h1atotb': -...  \n",
       " india_119120400390101  {'country': 0.0, 'h1atotb': 0.0, 'h1child': 0....  \n",
       " mexico_1232510         {'country': 0.0, 'h1atotb': 0.0, 'h1child': 0....  \n",
       " us_54616040            {'country': 0.003970272608674365, 'h1atotb': 0...  \n",
       " ...                                                                  ...  \n",
       " mexico_302210          {'country': 0.0, 'h1atotb': 0.0, 'h1child': 0....  \n",
       " us_111640010           {'country': 0.0, 'h1atotb': 0.0, 'h1child': 0....  \n",
       " india_129194300390101  {'country': -0.0003939805491131999, 'h1atotb':...  \n",
       " india_105025300020101  {'country': 0.0, 'h1atotb': 0.0, 'h1child': 0....  \n",
       " us_46686020            {'country': 0.0, 'h1atotb': 0.0, 'h1child': 0....  \n",
       " \n",
       " [800 rows x 2 columns],\n",
       " 'y_catb_test':                               y  \\\n",
       " id_resp                           \n",
       " us_74521010           -1.632004   \n",
       " mexico_787110         -1.741750   \n",
       " india_127182900171605  0.400321   \n",
       " india_105022700550102 -0.239407   \n",
       " india_124155301820102 -0.550303   \n",
       " ...                         ...   \n",
       " us_15189010           -0.129469   \n",
       " india_133219200780101  1.251039   \n",
       " us_500587010           0.080703   \n",
       " india_109062300150101 -0.680898   \n",
       " us_38520010            0.132228   \n",
       " \n",
       "                                                                     shap  \\\n",
       " id_resp                                                                    \n",
       " us_74521010            {'country': -0.0033018891052120046, 'h1atotb':...   \n",
       " mexico_787110          {'country': 0.0007822167576498226, 'h1atotb': ...   \n",
       " india_127182900171605  {'country': 0.004352960447963562, 'h1atotb': -...   \n",
       " india_105022700550102  {'country': 0.004352960447963562, 'h1atotb': -...   \n",
       " india_124155301820102  {'country': 0.004352960447963562, 'h1atotb': -...   \n",
       " ...                                                                  ...   \n",
       " us_15189010            {'country': -0.0033018891052120046, 'h1atotb':...   \n",
       " india_133219200780101  {'country': 0.004352960447963562, 'h1atotb': -...   \n",
       " us_500587010           {'country': -0.0033018891052120046, 'h1atotb':...   \n",
       " india_109062300150101  {'country': 0.004352960447963562, 'h1atotb': -...   \n",
       " us_38520010            {'country': 0.0007822167576498226, 'h1atotb': ...   \n",
       " \n",
       "                         y_lower   y_upper  \n",
       " id_resp                                    \n",
       " us_74521010           -2.866387 -0.215578  \n",
       " mexico_787110         -3.003300 -0.349334  \n",
       " india_127182900171605 -0.857101  1.764711  \n",
       " india_105022700550102 -1.542425  1.088674  \n",
       " india_124155301820102 -1.957762  0.654488  \n",
       " ...                         ...       ...  \n",
       " us_15189010           -1.796581  0.807229  \n",
       " india_133219200780101 -0.056768  2.598361  \n",
       " us_500587010          -1.039702  1.557420  \n",
       " india_109062300150101 -2.060611  0.565818  \n",
       " us_38520010           -1.168415  1.480561  \n",
       " \n",
       " [200 rows x 4 columns],\n",
       " 'y_xgbm_train':                               y  \\\n",
       " id_resp                           \n",
       " us_912065010           0.376406   \n",
       " us_906682010          -0.052155   \n",
       " india_119120400390101  0.868083   \n",
       " mexico_1232510        -1.123374   \n",
       " us_54616040           -0.550196   \n",
       " ...                         ...   \n",
       " mexico_302210         -0.713099   \n",
       " us_111640010           0.263088   \n",
       " india_129194300390101 -0.619854   \n",
       " india_105025300020101 -0.455208   \n",
       " us_46686020            1.107846   \n",
       " \n",
       "                                                                     shap  \n",
       " id_resp                                                                   \n",
       " us_912065010           {'country': 0.0003058645, 'h1atotb': 0.0005908...  \n",
       " us_906682010           {'country': -0.0007270115, 'h1atotb': -0.00594...  \n",
       " india_119120400390101  {'country': -0.00012572978, 'h1atotb': -0.0038...  \n",
       " mexico_1232510         {'country': -0.00016286813, 'h1atotb': -0.0016...  \n",
       " us_54616040            {'country': -0.00035585754, 'h1atotb': -0.0238...  \n",
       " ...                                                                  ...  \n",
       " mexico_302210          {'country': -0.00031177522, 'h1atotb': -0.0023...  \n",
       " us_111640010           {'country': 0.00034347767, 'h1atotb': -0.02207...  \n",
       " india_129194300390101  {'country': 2.1609252e-05, 'h1atotb': -0.00299...  \n",
       " india_105025300020101  {'country': -0.0001401544, 'h1atotb': -0.00288...  \n",
       " us_46686020            {'country': 0.00051305763, 'h1atotb': -4.31575...  \n",
       " \n",
       " [800 rows x 2 columns],\n",
       " 'y_xgbm_test':                               y  \\\n",
       " id_resp                           \n",
       " us_74521010           -1.720257   \n",
       " mexico_787110         -1.812808   \n",
       " india_127182900171605  0.516805   \n",
       " india_105022700550102 -0.255740   \n",
       " india_124155301820102 -0.903288   \n",
       " ...                         ...   \n",
       " us_15189010           -0.615528   \n",
       " india_133219200780101  1.240924   \n",
       " us_500587010           0.130921   \n",
       " india_109062300150101 -0.967812   \n",
       " us_38520010            0.311778   \n",
       " \n",
       "                                                                     shap  \\\n",
       " id_resp                                                                    \n",
       " us_74521010            {'country': -3.708608e-05, 'h1atotb': -0.02219...   \n",
       " mexico_787110          {'country': -0.00026219094, 'h1atotb': -0.0193...   \n",
       " india_127182900171605  {'country': -1.6927144e-05, 'h1atotb': -0.0031...   \n",
       " india_105022700550102  {'country': -5.0071754e-05, 'h1atotb': -0.0038...   \n",
       " india_124155301820102  {'country': -4.480935e-06, 'h1atotb': -0.00197...   \n",
       " ...                                                                  ...   \n",
       " us_15189010            {'country': -3.708608e-05, 'h1atotb': -0.02728...   \n",
       " india_133219200780101  {'country': -1.6927144e-05, 'h1atotb': -0.0041...   \n",
       " us_500587010           {'country': -3.708608e-05, 'h1atotb': -0.00501...   \n",
       " india_109062300150101  {'country': 0.002130634, 'h1atotb': -0.0178999...   \n",
       " us_38520010            {'country': -0.0054059895, 'h1atotb': 0.041576...   \n",
       " \n",
       "                         y_lower   y_upper  \n",
       " id_resp                                    \n",
       " us_74521010           -3.062301 -0.266738  \n",
       " mexico_787110         -3.260853 -0.491314  \n",
       " india_127182900171605 -0.840652  1.858696  \n",
       " india_105022700550102 -1.596530  1.092662  \n",
       " india_124155301820102 -2.186911  0.617774  \n",
       " ...                         ...       ...  \n",
       " us_15189010           -1.944004  0.868469  \n",
       " india_133219200780101 -0.186556  2.593815  \n",
       " us_500587010          -1.394622  1.703117  \n",
       " india_109062300150101 -2.368632  0.337020  \n",
       " us_38520010           -1.298327  1.598245  \n",
       " \n",
       " [200 rows x 4 columns],\n",
       " 'y_ensb_train':                               y  \\\n",
       " id_resp                           \n",
       " us_912065010           0.422965   \n",
       " us_906682010           0.011722   \n",
       " india_119120400390101  0.789967   \n",
       " mexico_1232510        -1.000902   \n",
       " us_54616040            -0.59618   \n",
       " ...                         ...   \n",
       " mexico_302210         -0.810544   \n",
       " us_111640010            0.53017   \n",
       " india_129194300390101 -0.611066   \n",
       " india_105025300020101  -0.55255   \n",
       " us_46686020            0.886895   \n",
       " \n",
       "                                                                     shap  \n",
       " id_resp                                                                   \n",
       " us_912065010           {'country': 0.00010095426470339265, 'h1atotb':...  \n",
       " us_906682010           {'country': 0.0010870374680783973, 'h1atotb': ...  \n",
       " india_119120400390101  {'country': -4.136366627147704e-05, 'h1atotb':...  \n",
       " mexico_1232510         {'country': -5.4905428292971066e-05, 'h1atotb'...  \n",
       " us_54616040            {'country': 0.001219514904939281, 'h1atotb': -...  \n",
       " ...                                                                  ...  \n",
       " mexico_302210          {'country': -0.00010164791081156568, 'h1atotb'...  \n",
       " us_111640010           {'country': 0.00011198384494767738, 'h1atotb':...  \n",
       " india_129194300390101  {'country': -0.00012441383636188673, 'h1atotb'...  \n",
       " india_105025300020101  {'country': -4.5640773882320467e-05, 'h1atotb'...  \n",
       " us_46686020            {'country': 0.0001677164476842144, 'h1atotb': ...  \n",
       " \n",
       " [800 rows x 2 columns],\n",
       " 'y_ensb_test':                               y  \\\n",
       " id_resp                           \n",
       " us_74521010           -1.591010   \n",
       " mexico_787110         -1.801646   \n",
       " india_127182900171605  0.454473   \n",
       " india_105022700550102 -0.207630   \n",
       " india_124155301820102 -0.753172   \n",
       " ...                         ...   \n",
       " us_15189010           -0.425912   \n",
       " india_133219200780101  1.305052   \n",
       " us_500587010           0.104746   \n",
       " india_109062300150101 -0.829663   \n",
       " us_38520010            0.137306   \n",
       " \n",
       "                                                                     shap  \\\n",
       " id_resp                                                                    \n",
       " us_74521010            {'country': 0.0002991900213966776, 'h1atotb': ...   \n",
       " mexico_787110          {'country': -0.0010831704664873289, 'h1atotb':...   \n",
       " india_127182900171605  {'country': 0.0001996325349850692, 'h1atotb': ...   \n",
       " india_105022700550102  {'country': 0.0010654176356304221, 'h1atotb': ...   \n",
       " india_124155301820102  {'country': 0.0010459884595009974, 'h1atotb': ...   \n",
       " ...                                                                  ...   \n",
       " us_15189010            {'country': 0.00029727688880342123, 'h1atotb':...   \n",
       " india_133219200780101  {'country': 0.001276686371102761, 'h1atotb': -...   \n",
       " us_500587010           {'country': -0.0009802389986212285, 'h1atotb':...   \n",
       " india_109062300150101  {'country': 0.0018415313492639953, 'h1atotb': ...   \n",
       " us_38520010            {'country': -6.965195081603496e-05, 'h1atotb':...   \n",
       " \n",
       "                         y_lower   y_upper  \n",
       " id_resp                                    \n",
       " us_74521010           -2.906629 -0.229481  \n",
       " mexico_787110         -3.136804 -0.447835  \n",
       " india_127182900171605 -0.824432  1.821089  \n",
       " india_105022700550102 -1.539314  1.107404  \n",
       " india_124155301820102 -2.057498  0.609031  \n",
       " ...                         ...       ...  \n",
       " us_15189010           -1.888263  0.786725  \n",
       " india_133219200780101 -0.081859  2.597392  \n",
       " us_500587010          -1.160645  1.600578  \n",
       " india_109062300150101 -2.188386  0.447983  \n",
       " us_38520010           -1.223392  1.486098  \n",
       " \n",
       " [200 rows x 4 columns]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ba9df3",
   "metadata": {},
   "source": [
    "# 2. Train on one dataset and predict on a completely new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "330ccd69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Example 2: Train on one dataset and predict on new data ===\n",
      "\n",
      "Training pipeline on initial dataset...\n",
      "=== Starting Full Pipeline ===\n",
      "Loading data...\n",
      "Using random 0.2 split...\n",
      "Train set: 800 samples\n",
      "Test set: 200 samples\n",
      "Running data preprocessing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/social_determinants_env/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:246: UserWarning: Found unknown categories in columns [5, 7, 10, 74, 107, 110, 116, 117] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 19:30:51,168] A new study created in memory with name: no-name-0217bf2c-ec81-4a28-a8a9-8ed3a98f8bf3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing complete. Features: 568\n",
      "Training LGBM model...\n",
      "  Optimizing lgbm hyperparameters...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\tvalid_0's rmse: 0.661833\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's rmse: 0.787725\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-15 19:30:53,718] Trial 0 finished with value: 0.5233249867519968 and parameters: {'lambda_l1': 0.024289169469748875, 'lambda_l2': 3.2859708169642414, 'num_leaves': 99, 'feature_fraction': 0.8394633936788146, 'bagging_fraction': 0.6468055921327309, 'bagging_freq': 1, 'min_child_samples': 12, 'learning_rate': 0.146962368105409}. Best is trial 0 with value: 0.5233249867519968.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's rmse: 0.6685\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[90]\tvalid_0's rmse: 0.710643\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[81]\tvalid_0's rmse: 0.658164\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-15 19:30:56,511] Trial 1 finished with value: 0.5035678610523731 and parameters: {'lambda_l1': 0.16730402817820234, 'lambda_l2': 0.4160439645256604, 'num_leaves': 22, 'feature_fraction': 0.9879639408647978, 'bagging_fraction': 0.8497327922401265, 'bagging_freq': 1, 'min_child_samples': 17, 'learning_rate': 0.03050945891610522}. Best is trial 1 with value: 0.5035678610523731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[99]\tvalid_0's rmse: 0.740006\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[77]\tvalid_0's rmse: 0.657323\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[80]\tvalid_0's rmse: 0.718042\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[65]\tvalid_0's rmse: 0.66403\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[95]\tvalid_0's rmse: 0.763226\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-15 19:30:58,853] Trial 2 finished with value: 0.4974375250601743 and parameters: {'lambda_l1': 0.01334697757417809, 'lambda_l2': 0.08730885649333642, 'num_leaves': 67, 'feature_fraction': 0.7164916560792167, 'bagging_fraction': 0.7835558684167139, 'bagging_freq': 1, 'min_child_samples': 21, 'learning_rate': 0.04649345697900868}. Best is trial 2 with value: 0.4974375250601743.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's rmse: 0.718388\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's rmse: 0.664192\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[99]\tvalid_0's rmse: 0.653427\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-15 19:31:00,382] Trial 3 finished with value: 0.4952746594299272 and parameters: {'lambda_l1': 0.04863951003835899, 'lambda_l2': 0.8023102291340046, 'num_leaves': 41, 'feature_fraction': 0.8056937753654446, 'bagging_fraction': 0.7777243706586128, 'bagging_freq': 1, 'min_child_samples': 34, 'learning_rate': 0.029617890239950373}. Best is trial 3 with value: 0.4952746594299272.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's rmse: 0.725761\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[58]\tvalid_0's rmse: 0.646849\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-15 19:31:01,667] Trial 4 finished with value: 0.48142056610125794 and parameters: {'lambda_l1': 0.0017402990823522548, 'lambda_l2': 3.235185145617431, 'num_leaves': 125, 'feature_fraction': 0.9233589392465844, 'bagging_fraction': 0.6913841307520112, 'bagging_freq': 1, 'min_child_samples': 38, 'learning_rate': 0.05510391929902154}. Best is trial 4 with value: 0.48142056610125794.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[99]\tvalid_0's rmse: 0.710159\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[66]\tvalid_0's rmse: 0.708318\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\tvalid_0's rmse: 0.65519\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-15 19:31:03,531] Trial 5 finished with value: 0.4932084235116639 and parameters: {'lambda_l1': 0.002827585657311758, 'lambda_l2': 0.06786479434196534, 'num_leaves': 23, 'feature_fraction': 0.9637281608315128, 'bagging_fraction': 0.677633994480005, 'bagging_freq': 2, 'min_child_samples': 22, 'learning_rate': 0.06623659776144764}. Best is trial 4 with value: 0.48142056610125794.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's rmse: 0.750436\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-15 19:31:04,888] Trial 6 finished with value: 0.5093660392916048 and parameters: {'lambda_l1': 0.105260377776104, 'lambda_l2': 0.0048280425192712886, 'num_leaves': 125, 'feature_fraction': 0.9100531293444458, 'bagging_fraction': 0.8818496824692568, 'bagging_freq': 3, 'min_child_samples': 34, 'learning_rate': 0.16707221510623524}. Best is trial 4 with value: 0.48142056610125794.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-15 19:31:06,128] Trial 7 finished with value: 0.4894836019603163 and parameters: {'lambda_l1': 0.002124863863243128, 'lambda_l2': 0.005308046630775945, 'num_leaves': 24, 'feature_fraction': 0.7301321323053057, 'bagging_fraction': 0.7166031869068445, 'bagging_freq': 1, 'min_child_samples': 43, 'learning_rate': 0.04547611147126364}. Best is trial 4 with value: 0.48142056610125794.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's rmse: 0.732461\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's rmse: 0.664826\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[93]\tvalid_0's rmse: 0.709832\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's rmse: 0.658554\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[99]\tvalid_0's rmse: 0.75915\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-15 19:31:07,216] Trial 8 finished with value: 0.5027633294110772 and parameters: {'lambda_l1': 0.010943804457233497, 'lambda_l2': 0.10172238474449048, 'num_leaves': 35, 'feature_fraction': 0.9208787923016158, 'bagging_fraction': 0.6223651931039312, 'bagging_freq': 3, 'min_child_samples': 41, 'learning_rate': 0.031604263728207765}. Best is trial 4 with value: 0.48142056610125794.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's rmse: 0.746966\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's rmse: 0.662284\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's rmse: 0.716216\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[97]\tvalid_0's rmse: 0.663683\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's rmse: 0.77099\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-15 19:31:09,313] Trial 9 finished with value: 0.5051376883780595 and parameters: {'lambda_l1': 0.0010481565330759974, 'lambda_l2': 1.0384064176934509, 'num_leaves': 97, 'feature_fraction': 0.8916028672163949, 'bagging_fraction': 0.8313811040057837, 'bagging_freq': 1, 'min_child_samples': 24, 'learning_rate': 0.02611554269799446}. Best is trial 4 with value: 0.48142056610125794.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's rmse: 0.734304\n",
      "  Parameters optimized\n",
      "  Fitting lgbm model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/social_determinants_env/lib/python3.11/site-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
      "  _log_warning(\"Only training set found, disabling early stopping.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  lgbm model saved\n",
      "  Generating lgbm predictions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-15 19:31:10,776] A new study created in memory with name: no-name-0086ec7a-ad20-40ef-b65e-90159fcab73e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  lgbm predictions saved\n",
      "Training CATB model...\n",
      "  Optimizing catb hyperparameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-15 19:31:11,715] Trial 0 finished with value: 0.49729263054409883 and parameters: {'depth': 5, 'learning_rate': 0.1785436060870726, 'l2_leaf_reg': 5.395030966670228, 'bagging_temperature': 0.2993292420985183}. Best is trial 0 with value: 0.49729263054409883.\n",
      "[I 2025-07-15 19:31:12,430] Trial 1 finished with value: 0.546967354976403 and parameters: {'depth': 4, 'learning_rate': 0.02864339657822303, 'l2_leaf_reg': 1.1430983876313219, 'bagging_temperature': 0.4330880728874676}. Best is trial 0 with value: 0.49729263054409883.\n",
      "[I 2025-07-15 19:31:13,730] Trial 2 finished with value: 0.49912022773787246 and parameters: {'depth': 6, 'learning_rate': 0.10211806418789517, 'l2_leaf_reg': 1.0485387725194617, 'bagging_temperature': 0.48495492608099716}. Best is trial 0 with value: 0.49729263054409883.\n",
      "[I 2025-07-15 19:31:15,696] Trial 3 finished with value: 0.5156374799069744 and parameters: {'depth': 7, 'learning_rate': 0.03261137469244295, 'l2_leaf_reg': 1.5199348301309807, 'bagging_temperature': 0.09170225492671691}. Best is trial 0 with value: 0.49729263054409883.\n",
      "[I 2025-07-15 19:31:16,645] Trial 4 finished with value: 0.49986230700551654 and parameters: {'depth': 5, 'learning_rate': 0.06695552617031866, 'l2_leaf_reg': 2.7036160666620015, 'bagging_temperature': 0.14561457009902096}. Best is trial 0 with value: 0.49729263054409883.\n",
      "[I 2025-07-15 19:31:17,988] Trial 5 finished with value: 0.5345966715381458 and parameters: {'depth': 6, 'learning_rate': 0.027575529238707534, 'l2_leaf_reg': 1.9594972058679163, 'bagging_temperature': 0.18318092164684585}. Best is trial 0 with value: 0.49729263054409883.\n",
      "[I 2025-07-15 19:31:18,968] Trial 6 finished with value: 0.49228430661459566 and parameters: {'depth': 5, 'learning_rate': 0.12195678219063029, 'l2_leaf_reg': 1.5837031559118748, 'bagging_temperature': 0.2571172192068058}. Best is trial 6 with value: 0.49228430661459566.\n",
      "[I 2025-07-15 19:31:20,296] Trial 7 finished with value: 0.5692878371979371 and parameters: {'depth': 6, 'learning_rate': 0.022257706349811456, 'l2_leaf_reg': 4.050837781329674, 'bagging_temperature': 0.08526206184364576}. Best is trial 6 with value: 0.49228430661459566.\n",
      "[I 2025-07-15 19:31:21,008] Trial 8 finished with value: 0.5046877862830282 and parameters: {'depth': 4, 'learning_rate': 0.1777933581403786, 'l2_leaf_reg': 9.23915031962725, 'bagging_temperature': 0.40419867405823057}. Best is trial 6 with value: 0.49228430661459566.\n",
      "[I 2025-07-15 19:31:21,999] Trial 9 finished with value: 0.5621124512540027 and parameters: {'depth': 5, 'learning_rate': 0.025043908574120786, 'l2_leaf_reg': 4.833180632488465, 'bagging_temperature': 0.22007624686980065}. Best is trial 6 with value: 0.49228430661459566.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Parameters optimized\n",
      "  Fitting catb model...\n",
      "  catb model saved\n",
      "  Generating catb predictions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-15 19:31:23,087] A new study created in memory with name: no-name-41fb5199-6576-4ae3-a2c9-589c53ae9861\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  catb predictions saved\n",
      "Training XGBM model...\n",
      "  Optimizing xgbm hyperparameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-15 19:31:24,922] Trial 0 finished with value: 0.5403471132133384 and parameters: {'max_depth': 5, 'learning_rate': 0.1785436060870726, 'subsample': 0.892797576724562, 'colsample_bytree': 0.8394633936788146, 'reg_alpha': 0.0029380279387035343, 'reg_lambda': 0.026364803038431653}. Best is trial 0 with value: 0.5403471132133384.\n",
      "[I 2025-07-15 19:31:26,715] Trial 1 finished with value: 0.5013058877116958 and parameters: {'max_depth': 4, 'learning_rate': 0.146962368105409, 'subsample': 0.8404460046972835, 'colsample_bytree': 0.8832290311184181, 'reg_alpha': 0.00115279871282324, 'reg_lambda': 4.147225000481636}. Best is trial 1 with value: 0.5013058877116958.\n",
      "[I 2025-07-15 19:31:29,515] Trial 2 finished with value: 0.5322434549188729 and parameters: {'max_depth': 7, 'learning_rate': 0.03261137469244295, 'subsample': 0.6727299868828402, 'colsample_bytree': 0.6733618039413735, 'reg_alpha': 0.008179499475211672, 'reg_lambda': 0.2607965659809584}. Best is trial 1 with value: 0.5013058877116958.\n",
      "[I 2025-07-15 19:31:31,747] Trial 3 finished with value: 0.5242362973999866 and parameters: {'max_depth': 5, 'learning_rate': 0.039107417325490494, 'subsample': 0.8447411578889518, 'colsample_bytree': 0.6557975442608167, 'reg_alpha': 0.007523742884534853, 'reg_lambda': 0.09745399020374085}. Best is trial 1 with value: 0.5013058877116958.\n",
      "[I 2025-07-15 19:31:33,768] Trial 4 finished with value: 0.5257883111540781 and parameters: {'max_depth': 5, 'learning_rate': 0.12195678219063029, 'subsample': 0.6798695128633439, 'colsample_bytree': 0.8056937753654446, 'reg_alpha': 0.05987474910461398, 'reg_lambda': 0.013346527038305937}. Best is trial 1 with value: 0.5013058877116958.\n",
      "[I 2025-07-15 19:31:36,385] Trial 5 finished with value: 0.5115806974101986 and parameters: {'max_depth': 6, 'learning_rate': 0.029617890239950373, 'subsample': 0.6260206371941118, 'colsample_bytree': 0.9795542149013333, 'reg_alpha': 0.7886714129990487, 'reg_lambda': 1.519988122008397}. Best is trial 1 with value: 0.5013058877116958.\n",
      "[I 2025-07-15 19:31:38,684] Trial 6 finished with value: 0.5351617913785771 and parameters: {'max_depth': 5, 'learning_rate': 0.025043908574120786, 'subsample': 0.8736932106048627, 'colsample_bytree': 0.7760609974958406, 'reg_alpha': 0.002323350351539011, 'reg_lambda': 0.21700394405050152}. Best is trial 1 with value: 0.5013058877116958.\n",
      "[I 2025-07-15 19:31:40,402] Trial 7 finished with value: 0.5227395929974393 and parameters: {'max_depth': 4, 'learning_rate': 0.16231191351941007, 'subsample': 0.7035119926400067, 'colsample_bytree': 0.8650089137415928, 'reg_alpha': 0.00861257919259488, 'reg_lambda': 0.25330746540014476}. Best is trial 1 with value: 0.5013058877116958.\n",
      "[I 2025-07-15 19:31:43,324] Trial 8 finished with value: 0.543748211814513 and parameters: {'max_depth': 6, 'learning_rate': 0.030611488731000357, 'subsample': 0.9878338511058234, 'colsample_bytree': 0.9100531293444458, 'reg_alpha': 0.6584106160121609, 'reg_lambda': 2.6008312687264885}. Best is trial 1 with value: 0.5013058877116958.\n",
      "[I 2025-07-15 19:31:45,343] Trial 9 finished with value: 0.562226861466101 and parameters: {'max_depth': 6, 'learning_rate': 0.16707221510623524, 'subsample': 0.6353970008207678, 'colsample_bytree': 0.6783931449676581, 'reg_alpha': 0.0013667272915456222, 'reg_lambda': 0.07551909976018513}. Best is trial 1 with value: 0.5013058877116958.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Parameters optimized\n",
      "  Fitting xgbm model...\n",
      "  xgbm model saved\n",
      "  Generating xgbm predictions...\n",
      "  xgbm predictions saved\n",
      "Training ensemble model...\n",
      "Ensemble training complete\n",
      "Final predictions saved to: predictions_train_example.pkl\n",
      "=== Pipeline Complete ===\n",
      "\n",
      "Preparing new dataset for prediction...\n",
      "\n",
      "Making predictions on new dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/social_determinants_env/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:246: UserWarning: Found unknown categories in columns [2, 5, 7, 10, 100, 110, 117] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 2. Train on one dataset and predict on a completely new dataset\n",
    "print(\"=== Example 2: Train on one dataset and predict on new data ===\")\n",
    "\n",
    "# First, let's train the pipeline on our training dataset\n",
    "train_runner = PipelineRunner(\n",
    "    data_dir='../data',\n",
    "    models_dir='../models',\n",
    "    run_name='train_example',\n",
    "    df_combined_path='../data/processed/df_combined_sample.pkl',\n",
    "    variables_type_path='../data/variables/table_variables_type.xlsx',\n",
    "    return_shap=False,\n",
    "    return_ci=False\n",
    ")\n",
    "\n",
    "# Run the full pipeline on training data\n",
    "print(\"\\nTraining pipeline on initial dataset...\")\n",
    "train_predictions = train_runner.run_full_pipeline()\n",
    "\n",
    "# Now let's simulate a completely new dataset (in practice, this would be your new data)\n",
    "# For this example, we'll create a new sample with different random seed\n",
    "print(\"\\nPreparing new dataset for prediction...\")\n",
    "df_new = pd.read_pickle('../data/processed/df_combined.pkl').sample(200, random_state=100)\n",
    "df_new.to_pickle('../data/processed/df_new_data.pkl')\n",
    "\n",
    "# Make predictions on the new dataset\n",
    "print(\"\\nMaking predictions on new dataset...\")\n",
    "new_predictions = train_runner.predict_new_data(df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5ebccc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lgbm':                               y\n",
       " id_resp                        \n",
       " mexico_1488220        -0.866992\n",
       " us_201780021          -0.160098\n",
       " india_108045001340107 -0.944540\n",
       " us_54620010            0.958138\n",
       " india_127179800030407  0.955335\n",
       " ...                         ...\n",
       " uk_112801              0.835175\n",
       " us_32256020            0.405579\n",
       " us_73878010            0.234891\n",
       " uk_106815              0.399510\n",
       " india_121132802390101  0.454540\n",
       " \n",
       " [200 rows x 1 columns],\n",
       " 'catb':                               y\n",
       " id_resp                        \n",
       " mexico_1488220        -0.903571\n",
       " us_201780021          -0.140253\n",
       " india_108045001340107 -0.590294\n",
       " us_54620010            0.672366\n",
       " india_127179800030407  0.817517\n",
       " ...                         ...\n",
       " uk_112801              0.977879\n",
       " us_32256020            0.235562\n",
       " us_73878010            0.507392\n",
       " uk_106815              0.136192\n",
       " india_121132802390101  0.350190\n",
       " \n",
       " [200 rows x 1 columns],\n",
       " 'xgbm':                               y\n",
       " id_resp                        \n",
       " mexico_1488220        -1.443022\n",
       " us_201780021           0.037074\n",
       " india_108045001340107 -0.593865\n",
       " us_54620010            0.923507\n",
       " india_127179800030407  1.168211\n",
       " ...                         ...\n",
       " uk_112801              1.095606\n",
       " us_32256020            0.652251\n",
       " us_73878010            0.090643\n",
       " uk_106815              0.640002\n",
       " india_121132802390101  0.541943\n",
       " \n",
       " [200 rows x 1 columns],\n",
       " 'ensemble':                               y\n",
       " id_resp                        \n",
       " mexico_1488220        -1.068694\n",
       " us_201780021          -0.088849\n",
       " india_108045001340107 -0.710370\n",
       " us_54620010            0.850359\n",
       " india_127179800030407  0.979460\n",
       " ...                         ...\n",
       " uk_112801              0.968398\n",
       " us_32256020            0.428477\n",
       " us_73878010            0.279948\n",
       " uk_106815              0.388889\n",
       " india_121132802390101  0.447758\n",
       " \n",
       " [200 rows x 1 columns]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df83e5ae",
   "metadata": {},
   "source": [
    "# 3. Fairness-Aware Training Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93d744ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Example 3: Fairness-Aware Training ===\n",
      "\n",
      "Training pipeline with fairness awareness for country...\n",
      "=== Starting Full Pipeline ===\n",
      "Loading data...\n",
      "Using random 0.2 split...\n",
      "Train set: 800 samples\n",
      "Test set: 200 samples\n",
      "Running data preprocessing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/social_determinants_env/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:246: UserWarning: Found unknown categories in columns [5, 7, 10, 74, 107, 110, 116, 117] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "[I 2025-07-15 19:31:47,631] A new study created in memory with name: no-name-ba791cb7-7110-422d-b8bb-426f94e8ebd7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing complete. Features: 568\n",
      "Training LGBM model...\n",
      "  Optimizing lgbm hyperparameters...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's rmse: 0.752156\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's rmse: 0.787725\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-15 19:31:50,496] Trial 0 finished with value: 0.5233249867519968 and parameters: {'lambda_l1': 0.024289169469748875, 'lambda_l2': 3.2859708169642414, 'num_leaves': 99, 'feature_fraction': 0.8394633936788146, 'bagging_fraction': 0.6468055921327309, 'bagging_freq': 1, 'min_child_samples': 12, 'learning_rate': 0.146962368105409}. Best is trial 0 with value: 0.5233249867519968.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[90]\tvalid_0's rmse: 0.710643\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-15 19:31:53,218] Trial 1 finished with value: 0.5035678610523731 and parameters: {'lambda_l1': 0.16730402817820234, 'lambda_l2': 0.4160439645256604, 'num_leaves': 22, 'feature_fraction': 0.9879639408647978, 'bagging_fraction': 0.8497327922401265, 'bagging_freq': 1, 'min_child_samples': 17, 'learning_rate': 0.03050945891610522}. Best is trial 1 with value: 0.5035678610523731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[77]\tvalid_0's rmse: 0.657323\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[80]\tvalid_0's rmse: 0.718042\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[65]\tvalid_0's rmse: 0.66403\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-15 19:31:55,686] Trial 2 finished with value: 0.4974375250601743 and parameters: {'lambda_l1': 0.01334697757417809, 'lambda_l2': 0.08730885649333642, 'num_leaves': 67, 'feature_fraction': 0.7164916560792167, 'bagging_fraction': 0.7835558684167139, 'bagging_freq': 1, 'min_child_samples': 21, 'learning_rate': 0.04649345697900868}. Best is trial 2 with value: 0.4974375250601743.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[99]\tvalid_0's rmse: 0.709308\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[99]\tvalid_0's rmse: 0.653427\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's rmse: 0.760532\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-15 19:31:57,165] Trial 3 finished with value: 0.4952746594299272 and parameters: {'lambda_l1': 0.04863951003835899, 'lambda_l2': 0.8023102291340046, 'num_leaves': 41, 'feature_fraction': 0.8056937753654446, 'bagging_fraction': 0.7777243706586128, 'bagging_freq': 1, 'min_child_samples': 34, 'learning_rate': 0.029617890239950373}. Best is trial 3 with value: 0.4952746594299272.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's rmse: 0.725761\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[75]\tvalid_0's rmse: 0.71024\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[58]\tvalid_0's rmse: 0.646849\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-15 19:31:58,456] Trial 4 finished with value: 0.48142056610125794 and parameters: {'lambda_l1': 0.0017402990823522548, 'lambda_l2': 3.235185145617431, 'num_leaves': 125, 'feature_fraction': 0.9233589392465844, 'bagging_fraction': 0.6913841307520112, 'bagging_freq': 1, 'min_child_samples': 38, 'learning_rate': 0.05510391929902154}. Best is trial 4 with value: 0.48142056610125794.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[99]\tvalid_0's rmse: 0.710159\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[62]\tvalid_0's rmse: 0.76911\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-15 19:32:00,337] Trial 5 finished with value: 0.4932084235116639 and parameters: {'lambda_l1': 0.002827585657311758, 'lambda_l2': 0.06786479434196534, 'num_leaves': 23, 'feature_fraction': 0.9637281608315128, 'bagging_fraction': 0.677633994480005, 'bagging_freq': 2, 'min_child_samples': 22, 'learning_rate': 0.06623659776144764}. Best is trial 4 with value: 0.48142056610125794.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\tvalid_0's rmse: 0.664224\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\tvalid_0's rmse: 0.771306\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-15 19:32:01,685] Trial 6 finished with value: 0.5093660392916048 and parameters: {'lambda_l1': 0.105260377776104, 'lambda_l2': 0.0048280425192712886, 'num_leaves': 125, 'feature_fraction': 0.9100531293444458, 'bagging_fraction': 0.8818496824692568, 'bagging_freq': 3, 'min_child_samples': 34, 'learning_rate': 0.16707221510623524}. Best is trial 4 with value: 0.48142056610125794.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[99]\tvalid_0's rmse: 0.661202\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[99]\tvalid_0's rmse: 0.707225\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's rmse: 0.646215\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-15 19:32:02,907] Trial 7 finished with value: 0.4894836019603163 and parameters: {'lambda_l1': 0.002124863863243128, 'lambda_l2': 0.005308046630775945, 'num_leaves': 24, 'feature_fraction': 0.7301321323053057, 'bagging_fraction': 0.7166031869068445, 'bagging_freq': 1, 'min_child_samples': 43, 'learning_rate': 0.04547611147126364}. Best is trial 4 with value: 0.48142056610125794.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's rmse: 0.664826\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's rmse: 0.658554\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[99]\tvalid_0's rmse: 0.75915\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-15 19:32:03,949] Trial 8 finished with value: 0.5027633294110772 and parameters: {'lambda_l1': 0.010943804457233497, 'lambda_l2': 0.10172238474449048, 'num_leaves': 35, 'feature_fraction': 0.9208787923016158, 'bagging_fraction': 0.6223651931039312, 'bagging_freq': 3, 'min_child_samples': 41, 'learning_rate': 0.031604263728207765}. Best is trial 4 with value: 0.48142056610125794.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's rmse: 0.746966\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's rmse: 0.662284\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's rmse: 0.77099\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-15 19:32:06,128] Trial 9 finished with value: 0.5051376883780595 and parameters: {'lambda_l1': 0.0010481565330759974, 'lambda_l2': 1.0384064176934509, 'num_leaves': 97, 'feature_fraction': 0.8916028672163949, 'bagging_fraction': 0.8313811040057837, 'bagging_freq': 1, 'min_child_samples': 24, 'learning_rate': 0.02611554269799446}. Best is trial 4 with value: 0.48142056610125794.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's rmse: 0.734304\n",
      "  Parameters optimized\n",
      "  Fitting lgbm model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/social_determinants_env/lib/python3.11/site-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
      "  _log_warning(\"Only training set found, disabling early stopping.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  lgbm model saved\n",
      "  Generating lgbm predictions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-15 19:32:07,263] A new study created in memory with name: no-name-34432185-f942-4e56-b355-2f10c870b82b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  lgbm predictions saved\n",
      "Training CATB model...\n",
      "  Optimizing catb hyperparameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-15 19:32:08,239] Trial 0 finished with value: 0.49729263054409883 and parameters: {'depth': 5, 'learning_rate': 0.1785436060870726, 'l2_leaf_reg': 5.395030966670228, 'bagging_temperature': 0.2993292420985183}. Best is trial 0 with value: 0.49729263054409883.\n",
      "[I 2025-07-15 19:32:08,974] Trial 1 finished with value: 0.546967354976403 and parameters: {'depth': 4, 'learning_rate': 0.02864339657822303, 'l2_leaf_reg': 1.1430983876313219, 'bagging_temperature': 0.4330880728874676}. Best is trial 0 with value: 0.49729263054409883.\n",
      "[I 2025-07-15 19:32:10,300] Trial 2 finished with value: 0.49912022773787246 and parameters: {'depth': 6, 'learning_rate': 0.10211806418789517, 'l2_leaf_reg': 1.0485387725194617, 'bagging_temperature': 0.48495492608099716}. Best is trial 0 with value: 0.49729263054409883.\n",
      "[I 2025-07-15 19:32:12,464] Trial 3 finished with value: 0.5156374799069744 and parameters: {'depth': 7, 'learning_rate': 0.03261137469244295, 'l2_leaf_reg': 1.5199348301309807, 'bagging_temperature': 0.09170225492671691}. Best is trial 0 with value: 0.49729263054409883.\n",
      "[I 2025-07-15 19:32:13,432] Trial 4 finished with value: 0.49986230700551654 and parameters: {'depth': 5, 'learning_rate': 0.06695552617031866, 'l2_leaf_reg': 2.7036160666620015, 'bagging_temperature': 0.14561457009902096}. Best is trial 0 with value: 0.49729263054409883.\n",
      "[I 2025-07-15 19:32:14,795] Trial 5 finished with value: 0.5345966715381458 and parameters: {'depth': 6, 'learning_rate': 0.027575529238707534, 'l2_leaf_reg': 1.9594972058679163, 'bagging_temperature': 0.18318092164684585}. Best is trial 0 with value: 0.49729263054409883.\n",
      "[I 2025-07-15 19:32:15,778] Trial 6 finished with value: 0.49228430661459566 and parameters: {'depth': 5, 'learning_rate': 0.12195678219063029, 'l2_leaf_reg': 1.5837031559118748, 'bagging_temperature': 0.2571172192068058}. Best is trial 6 with value: 0.49228430661459566.\n",
      "[I 2025-07-15 19:32:17,159] Trial 7 finished with value: 0.5692878371979371 and parameters: {'depth': 6, 'learning_rate': 0.022257706349811456, 'l2_leaf_reg': 4.050837781329674, 'bagging_temperature': 0.08526206184364576}. Best is trial 6 with value: 0.49228430661459566.\n",
      "[I 2025-07-15 19:32:17,869] Trial 8 finished with value: 0.5046877862830282 and parameters: {'depth': 4, 'learning_rate': 0.1777933581403786, 'l2_leaf_reg': 9.23915031962725, 'bagging_temperature': 0.40419867405823057}. Best is trial 6 with value: 0.49228430661459566.\n",
      "[I 2025-07-15 19:32:18,816] Trial 9 finished with value: 0.5621124512540027 and parameters: {'depth': 5, 'learning_rate': 0.025043908574120786, 'l2_leaf_reg': 4.833180632488465, 'bagging_temperature': 0.22007624686980065}. Best is trial 6 with value: 0.49228430661459566.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Parameters optimized\n",
      "  Fitting catb model...\n",
      "  catb model saved\n",
      "  Generating catb predictions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-15 19:32:19,897] A new study created in memory with name: no-name-74f7d01b-39af-4c68-b4f6-c12822e9938b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  catb predictions saved\n",
      "Training XGBM model...\n",
      "  Optimizing xgbm hyperparameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-15 19:32:21,691] Trial 0 finished with value: 0.5403471132133384 and parameters: {'max_depth': 5, 'learning_rate': 0.1785436060870726, 'subsample': 0.892797576724562, 'colsample_bytree': 0.8394633936788146, 'reg_alpha': 0.0029380279387035343, 'reg_lambda': 0.026364803038431653}. Best is trial 0 with value: 0.5403471132133384.\n",
      "[I 2025-07-15 19:32:23,577] Trial 1 finished with value: 0.5013058877116958 and parameters: {'max_depth': 4, 'learning_rate': 0.146962368105409, 'subsample': 0.8404460046972835, 'colsample_bytree': 0.8832290311184181, 'reg_alpha': 0.00115279871282324, 'reg_lambda': 4.147225000481636}. Best is trial 1 with value: 0.5013058877116958.\n",
      "[I 2025-07-15 19:32:26,367] Trial 2 finished with value: 0.5322434549188729 and parameters: {'max_depth': 7, 'learning_rate': 0.03261137469244295, 'subsample': 0.6727299868828402, 'colsample_bytree': 0.6733618039413735, 'reg_alpha': 0.008179499475211672, 'reg_lambda': 0.2607965659809584}. Best is trial 1 with value: 0.5013058877116958.\n",
      "[I 2025-07-15 19:32:28,623] Trial 3 finished with value: 0.5242362973999866 and parameters: {'max_depth': 5, 'learning_rate': 0.039107417325490494, 'subsample': 0.8447411578889518, 'colsample_bytree': 0.6557975442608167, 'reg_alpha': 0.007523742884534853, 'reg_lambda': 0.09745399020374085}. Best is trial 1 with value: 0.5013058877116958.\n",
      "[I 2025-07-15 19:32:30,660] Trial 4 finished with value: 0.5257883111540781 and parameters: {'max_depth': 5, 'learning_rate': 0.12195678219063029, 'subsample': 0.6798695128633439, 'colsample_bytree': 0.8056937753654446, 'reg_alpha': 0.05987474910461398, 'reg_lambda': 0.013346527038305937}. Best is trial 1 with value: 0.5013058877116958.\n",
      "[I 2025-07-15 19:32:33,263] Trial 5 finished with value: 0.5115806974101986 and parameters: {'max_depth': 6, 'learning_rate': 0.029617890239950373, 'subsample': 0.6260206371941118, 'colsample_bytree': 0.9795542149013333, 'reg_alpha': 0.7886714129990487, 'reg_lambda': 1.519988122008397}. Best is trial 1 with value: 0.5013058877116958.\n",
      "[I 2025-07-15 19:32:35,589] Trial 6 finished with value: 0.5351617913785771 and parameters: {'max_depth': 5, 'learning_rate': 0.025043908574120786, 'subsample': 0.8736932106048627, 'colsample_bytree': 0.7760609974958406, 'reg_alpha': 0.002323350351539011, 'reg_lambda': 0.21700394405050152}. Best is trial 1 with value: 0.5013058877116958.\n",
      "[I 2025-07-15 19:32:37,310] Trial 7 finished with value: 0.5227395929974393 and parameters: {'max_depth': 4, 'learning_rate': 0.16231191351941007, 'subsample': 0.7035119926400067, 'colsample_bytree': 0.8650089137415928, 'reg_alpha': 0.00861257919259488, 'reg_lambda': 0.25330746540014476}. Best is trial 1 with value: 0.5013058877116958.\n",
      "[I 2025-07-15 19:32:39,995] Trial 8 finished with value: 0.543748211814513 and parameters: {'max_depth': 6, 'learning_rate': 0.030611488731000357, 'subsample': 0.9878338511058234, 'colsample_bytree': 0.9100531293444458, 'reg_alpha': 0.6584106160121609, 'reg_lambda': 2.6008312687264885}. Best is trial 1 with value: 0.5013058877116958.\n",
      "[I 2025-07-15 19:32:42,014] Trial 9 finished with value: 0.562226861466101 and parameters: {'max_depth': 6, 'learning_rate': 0.16707221510623524, 'subsample': 0.6353970008207678, 'colsample_bytree': 0.6783931449676581, 'reg_alpha': 0.0013667272915456222, 'reg_lambda': 0.07551909976018513}. Best is trial 1 with value: 0.5013058877116958.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Parameters optimized\n",
      "  Fitting xgbm model...\n",
      "  xgbm model saved\n",
      "  Generating xgbm predictions...\n",
      "  xgbm predictions saved\n",
      "Training ensemble model...\n",
      "Ensemble training complete\n",
      "Final predictions saved to: predictions_fair_example.pkl\n",
      "=== Pipeline Complete ===\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Example 3: Fairness-Aware Training ===\")\n",
    "\n",
    "# Initialize pipeline with fairness awareness for gender\n",
    "fair_runner = PipelineRunner(\n",
    "    data_dir='../data',\n",
    "    models_dir='../models',\n",
    "    run_name='fair_example',\n",
    "    df_combined_path='../data/processed/df_combined_sample.pkl',\n",
    "    variables_type_path='../data/variables/table_variables_type.xlsx',\n",
    "    return_shap=False,\n",
    "    return_ci=False,\n",
    "    fair_col='country'  # Using country for fairness weighting\n",
    ")\n",
    "\n",
    "# Run pipeline with fairness awareness\n",
    "print(\"\\nTraining pipeline with fairness awareness for country...\")\n",
    "fair_predictions = fair_runner.run_full_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31d1a077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'y_lgbm_train':                               y\n",
       " id_resp                        \n",
       " us_912065010           0.311002\n",
       " us_906682010           0.220767\n",
       " india_119120400390101  0.388511\n",
       " mexico_1232510        -0.668307\n",
       " us_54616040           -0.359951\n",
       " ...                         ...\n",
       " mexico_302210         -0.525360\n",
       " us_111640010           0.372817\n",
       " india_129194300390101 -0.194594\n",
       " india_105025300020101 -0.382994\n",
       " us_46686020            0.180828\n",
       " \n",
       " [800 rows x 1 columns],\n",
       " 'y_lgbm_test':                               y\n",
       " id_resp                        \n",
       " us_74521010           -0.827855\n",
       " mexico_787110         -0.821549\n",
       " india_127182900171605  0.382026\n",
       " india_105022700550102 -0.041595\n",
       " india_124155301820102 -0.132493\n",
       " ...                         ...\n",
       " us_15189010           -0.363553\n",
       " india_133219200780101  0.475134\n",
       " us_500587010           0.191084\n",
       " india_109062300150101 -0.562706\n",
       " us_38520010            0.024537\n",
       " \n",
       " [200 rows x 1 columns],\n",
       " 'y_catb_train':                               y\n",
       " id_resp                        \n",
       " us_912065010           0.497703\n",
       " us_906682010           0.196020\n",
       " india_119120400390101  0.871610\n",
       " mexico_1232510        -1.285007\n",
       " us_54616040           -0.218010\n",
       " ...                         ...\n",
       " mexico_302210         -0.474547\n",
       " us_111640010           0.728372\n",
       " india_129194300390101 -0.525441\n",
       " india_105025300020101 -0.445245\n",
       " us_46686020            0.594163\n",
       " \n",
       " [800 rows x 1 columns],\n",
       " 'y_catb_test':                               y\n",
       " id_resp                        \n",
       " us_74521010           -1.734002\n",
       " mexico_787110         -1.682353\n",
       " india_127182900171605  0.512704\n",
       " india_105022700550102 -0.283632\n",
       " india_124155301820102 -0.605235\n",
       " ...                         ...\n",
       " us_15189010           -0.500011\n",
       " india_133219200780101  1.258592\n",
       " us_500587010           0.300004\n",
       " india_109062300150101 -0.716048\n",
       " us_38520010            0.295646\n",
       " \n",
       " [200 rows x 1 columns],\n",
       " 'y_xgbm_train':                               y\n",
       " id_resp                        \n",
       " us_912065010           0.357140\n",
       " us_906682010           0.107383\n",
       " india_119120400390101  0.741077\n",
       " mexico_1232510        -0.719906\n",
       " us_54616040           -0.477689\n",
       " ...                         ...\n",
       " mexico_302210         -0.516463\n",
       " us_111640010           0.498783\n",
       " india_129194300390101 -0.088695\n",
       " india_105025300020101 -0.457643\n",
       " us_46686020            0.093506\n",
       " \n",
       " [800 rows x 1 columns],\n",
       " 'y_xgbm_test':                               y\n",
       " id_resp                        \n",
       " us_74521010           -1.090851\n",
       " mexico_787110         -0.922333\n",
       " india_127182900171605  0.723854\n",
       " india_105022700550102  0.032579\n",
       " india_124155301820102 -0.020394\n",
       " ...                         ...\n",
       " us_15189010           -0.330187\n",
       " india_133219200780101  0.696429\n",
       " us_500587010           0.468077\n",
       " india_109062300150101 -0.548813\n",
       " us_38520010            0.026310\n",
       " \n",
       " [200 rows x 1 columns],\n",
       " 'y_ensb_train':                               y\n",
       " id_resp                        \n",
       " us_912065010           0.391388\n",
       " us_906682010           0.174385\n",
       " india_119120400390101  0.672606\n",
       " mexico_1232510        -0.899489\n",
       " us_54616040           -0.343968\n",
       " ...                         ...\n",
       " mexico_302210         -0.504333\n",
       " us_111640010             0.5409\n",
       " india_129194300390101 -0.273782\n",
       " india_105025300020101 -0.430839\n",
       " us_46686020             0.30175\n",
       " \n",
       " [800 rows x 1 columns],\n",
       " 'y_ensb_test':                               y\n",
       " id_resp                        \n",
       " us_74521010           -1.239075\n",
       " mexico_787110         -1.179838\n",
       " india_127182900171605  0.540892\n",
       " india_105022700550102 -0.100820\n",
       " india_124155301820102 -0.265353\n",
       " ...                         ...\n",
       " us_15189010           -0.404432\n",
       " india_133219200780101  0.820735\n",
       " us_500587010           0.321259\n",
       " india_109062300150101 -0.616257\n",
       " us_38520010            0.122372\n",
       " \n",
       " [200 rows x 1 columns]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fair_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e66d27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "social_determinants_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
